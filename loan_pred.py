# -*- coding: utf-8 -*-
"""Loan_pred.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kXHVWA-8h31IvxTTtYs6Na1EpZP7keyg
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

dataset = pd.read_csv('train_u6lujuX_CVtuZ9i.csv')

"""***REMOVING OUTLIERS***"""

def remove_outliers_iqr(dataset, column, lower_bound_factor=1.5, upper_bound_factor=1.5):
    q1 = dataset[column].quantile(0.25)
    q3 = dataset[column].quantile(0.75)
    iqr = q3 - q1
    lower_bound = q1 - lower_bound_factor * iqr
    upper_bound = q3 + upper_bound_factor * iqr
    dataset_filtered = dataset.loc[(dataset[column] >= lower_bound) & (dataset[column] <= upper_bound)]
    return dataset_filtered

# Specify the columns with numerical data where you want to remove outliers
columns_with_numerical_data = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']

# Remove outliers from each column
for column in columns_with_numerical_data:
    dataset = remove_outliers_iqr(dataset, column)

X = dataset.iloc[:, :-1]
y = dataset.iloc[:, -1]

dataset

X

print(y)

"""TAKING CARE OF MISSING DATA"""

missing_data = X.isnull()
missing_count_per_column = missing_data.sum()

missing_count_per_column

mean_LoanAmount = X['LoanAmount'].mean()
X['LoanAmount'].fillna(mean_LoanAmount, inplace=True)

missing_data = X.isnull()
missing_count_per_column = missing_data.sum()

missing_count_per_column

mean_Loan_Amount_Term = X['Loan_Amount_Term'].mean()
X['Loan_Amount_Term'].fillna(mean_Loan_Amount_Term, inplace=True)

missing_data = X.isnull()
missing_count_per_column = missing_data.sum()

missing_count_per_column

mode_credit_history =  X['Credit_History'].mode()[0]
X['Credit_History'].fillna(mode_credit_history, inplace=True)

missing_data = X.isnull()
missing_count_per_column = missing_data.sum()

missing_count_per_column

mode_Gender = X['Gender'].mode()[0]
X['Gender'].fillna(mode_Gender, inplace=True)

missing_data = X.isnull()
missing_count_per_column = missing_data.sum()

missing_count_per_column

mode_Married = X['Married'].mode()[0]
X['Married'].fillna(mode_Married, inplace=True)

missing_data = X.isnull()
missing_count_per_column = missing_data.sum()

missing_count_per_column

mode_Dependents = X['Dependents'].mode()[0]
X['Dependents'].fillna(mode_Dependents, inplace=True)

missing_data = X.isnull()
missing_count_per_column = missing_data.sum()

missing_count_per_column

mode_Self_Employed = X['Self_Employed'].mode()[0]
X['Self_Employed'].fillna(mode_Self_Employed, inplace=True)

missing_data = X.isnull()
missing_count_per_column = missing_data.sum()

missing_count_per_column

"""ENCODING DEPENDENT DATA"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

y

"""***ENCODING INDEPENDENT DATA***"""

X= pd.get_dummies(X, columns=['Property_Area'])

X

X= pd.get_dummies(X, columns=['Gender'])
X

X= pd.get_dummies(X, columns=['Married'])

X= pd.get_dummies(X, columns=['Education'])

X= pd.get_dummies(X, columns=['Self_Employed'])

X

X= X.drop(columns=['Loan_ID'])

"""***SPLITTING INTO TRAINING AND TESTING SET***



"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)

X_train

X_test

X.dtypes

X['Dependents'] = X['Dependents'].replace('3+', '4')

X

X.dtypes

X['Dependents'] = X['Dependents'].astype(int)

X.dtypes

"""***FEATURE SCALING***"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""# ***KNN***"""

from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)
classifier.fit(X_train, y_train)

"""***CONFUSION MATRIX***"""

from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = classifier.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)

"""***PREDICTING TEST RESULTS***"""

print(y_pred,y_test)

"""***K FOLD CROSS VALIDATION***"""

from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)
print("Accuracy: {:.2f} %".format(accuracies.mean()*100))
print("Standard Deviation: {:.2f} %".format(accuracies.std()*100))

"""***GRID SEARCH***"""

knn = KNeighborsClassifier()
from sklearn.model_selection import GridSearchCV
k_range = list(range(1, 31))
param_grid = dict(n_neighbors=k_range)
grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy', return_train_score=False,verbose=1)
grid_search=grid.fit(X_train, y_train)
print(grid_search.best_params_)
accuracy = grid_search.best_score_ *100
print("Accuracy for our training dataset with tuning is : {:.2f}%".format(accuracy) )

"""# ***RANDOM FOREST***

***Training***
"""

from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(n_estimators = 20, criterion = 'entropy', random_state = 0)
classifier.fit(X_train, y_train)

"""***PREDICTING THE TEST RESULTS***"""

y_pred = classifier.predict(X_test)
print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))

""" ***CONFUSION MATRIX***"""

from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = classifier.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)

"""***KFOLD CROSS VALIDATION ***"""

from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)
print("Accuracy: {:.2f} %".format(accuracies.mean()*100))
print("Standard Deviation: {:.2f} %".format(accuracies.std()*100))

"""***GRID SEARCH***"""

rf = RandomForestClassifier()
grid_space={'max_depth':[3,5,10,None],
              'n_estimators':[10,100,200],
              'max_features':[1,3,5,7],
              'min_samples_leaf':[1,2,3],
              'min_samples_split':[1,2,3]
           }
from sklearn.model_selection import GridSearchCV

grid = GridSearchCV(rf,param_grid=grid_space,cv=3,scoring='accuracy')
model_grid = grid.fit(X_train,y_train)
print('Best hyperparameters are: '+str(model_grid.best_params_))
accuracy = grid_search.best_score_ *100
print("Accuracy for our training dataset with tuning is : {:.2f}%".format(accuracy) )

"""# ***DECISION TREE***

***Training***
"""

from sklearn.tree import DecisionTreeClassifier
classifier=DecisionTreeClassifier(criterion='entropy', random_state=0)
classifier.fit(X_train,y_train)

"""***CONFUSION*** ***MATRIX***"""

from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)

"""***PREDICTING THE TEST RESULTS***"""

y_pred = classifier.predict(X_test)
print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))

"""***K FOLD CROSS VALIDATION***"""

from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)
print("Accuracy: {:.2f} %".format(accuracies.mean()*100))
print("Standard Deviation: {:.2f} %".format(accuracies.std()*100))

"""***GRID SEARCH***

# ***KERNEL SVM***

***TRAINING***
"""

from sklearn.svm import SVC
classifier = SVC( probability=True,kernel = 'linear', random_state = 0)
classifier.fit(X_train, y_train)

"""***PREDICTING THE TEST RESULTS***"""

y_pred = classifier.predict(X_test)
print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))

"""***CONFUSION MATRIX***"""

from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)

"""***K-FOLD CROSS VALIDATION***"""

from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)
print("Accuracy: {:.2f} %".format(accuracies.mean()*100))
print("Standard Deviation: {:.2f} %".format(accuracies.std()*100))

"""***GRID SEARCH***"""

from sklearn.model_selection import GridSearchCV
parameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']},
              {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]
grid_search = GridSearchCV(estimator = classifier,
                           param_grid = parameters,
                           scoring = 'accuracy',
                           cv = 10,
                           n_jobs = -1)
grid_search.fit(X_train, y_train)
best_accuracy = grid_search.best_score_
best_parameters = grid_search.best_params_
print("Best Accuracy: {:.2f} %".format(best_accuracy*100))
print("Best Parameters:", best_parameters)

"""***PRECISION***"""

from sklearn.metrics import precision_score
precision = precision_score(y_test, y_pred)
print("Precision:", precision)

"""***RECALL***"""

from sklearn.metrics import recall_score
recall = recall_score(y_test, y_pred)
print("Recall:", recall)

"""***F1 SCORE***"""

from sklearn.metrics import f1_score
f1score = f1_score(y_test, y_pred)
print("F1 score:", f1score)

"""***AUC_ROC CURVE***"""

from sklearn.metrics import roc_auc_score, roc_curve
y_pred_probs = classifier.predict_proba(X_test)[:, 1]

# Calculate AUC-ROC score
auc_roc = roc_auc_score(y_test, y_pred_probs)
print("AUC-ROC:", auc_roc)

# Plot ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)
plt.plot(fpr, tpr, label='ROC Curve (AUC = {:.2f})'.format(auc_roc))
plt.plot([0, 1], [0, 1], 'k--')  # Diagonal dotted line (random classifier)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()